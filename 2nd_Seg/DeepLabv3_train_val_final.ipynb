{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json, pickle, time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from albumentations.augmentations.crops.transforms import CropNonEmptyMaskIfExists"
      ],
      "metadata": {
        "id": "MhcqFvppH-AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths and annotation loading\n",
        "DATA_ROOT = '/content/drive/MyDrive/pt_data'\n",
        "WEIGHTS_PATH = os.path.join(DATA_ROOT, 'model_weights')"
      ],
      "metadata": {
        "id": "jWGS66vBIazP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AIHUB_ANN = os.path.join(DATA_ROOT, 'aihub_annotations.json')\n",
        "RDD_ANN   = os.path.join(DATA_ROOT, 'rdd2022_train_annotations.json')"
      ],
      "metadata": {
        "id": "wdE6tBElIci8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_consolidate_annotations(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    consolidated = {}\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            fn = item.get('file_name') or item.get('filename')\n",
        "            if not fn: continue\n",
        "            base = os.path.splitext(fn)[0]\n",
        "            consolidated[base] = item\n",
        "    else:\n",
        "        for key, item in data.items():\n",
        "            base = os.path.splitext(key)[0]\n",
        "            consolidated[base] = item\n",
        "        for item in data.get('annotations', []):\n",
        "            fn = item.get('file_name')\n",
        "            if not fn: continue\n",
        "            base = os.path.splitext(fn)[0]\n",
        "            consolidated[base] = item\n",
        "    return consolidated"
      ],
      "metadata": {
        "id": "aS16gMLaIZWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_dict = {**load_and_consolidate_annotations(AIHUB_ANN)}\n",
        "            #**load_and_consolidate_annotations(RDD_ANN)}"
      ],
      "metadata": {
        "id": "VUrdI4HbIWap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PKL file lists\n",
        "train_pkls = glob.glob(os.path.join(DATA_ROOT, 'AIhub_Road/training_image_batch_*.pkl'))\n",
        "             #glob.glob(os.path.join(DATA_ROOT, 'RDD2022/rdd2022_train_image_batch_*.pkl'))\n",
        "val_pkls   = glob.glob(os.path.join(DATA_ROOT, 'AIhub_Road/validation_image_batch_*.pkl'))"
      ],
      "metadata": {
        "id": "x9JQdW1YIU4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_train_pkls = glob.glob(os.path.join(DATA_ROOT, 'RDD2022/rdd2022_train_image_batch_*.pkl'))"
      ],
      "metadata": {
        "id": "MpyJuoA5IxS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms and augmentation\n",
        "seg_tf = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "crop_fn = CropNonEmptyMaskIfExists(height=224, width=224)"
      ],
      "metadata": {
        "id": "PMYCIrGGITQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask creation\n",
        "def create_mask_binary(annotations, shape):\n",
        "    H, W = shape\n",
        "    mask = np.zeros((H, W), dtype=np.int64)\n",
        "    for ann in annotations:\n",
        "        x, y, w, h = ann['bbox']\n",
        "        x0, y0 = int(round(x)), int(round(y))\n",
        "        x1 = x0 + int(round(w)) - 1\n",
        "        y1 = y0 + int(round(h)) - 1\n",
        "        if x1 > x0 and y1 > y0:\n",
        "            mask[y0:y1+1, x0:x1+1] = 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "md7_2GTVIRlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "def get_deeplab_model(num_classes):\n",
        "    model = deeplabv3_resnet101(pretrained=True)\n",
        "    model.classifier = DeepLabHead(2048, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "st1_I0xHIQtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model     = get_deeplab_model(2).to(device)"
      ],
      "metadata": {
        "id": "z5_RiyCSIKLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler    = GradScaler()\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "i1SpAyG2IMcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_bs    = 16 # batch_size\n",
        "epochs    = 10"
      ],
      "metadata": {
        "id": "tVIjJxo4IJBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shared batch processing\n",
        "def process_slice(slice_batch):\n",
        "    imgs, masks = [], []\n",
        "    for entry in slice_batch:\n",
        "        fn, arr = entry.get('filename'), entry.get('image')\n",
        "        anns = ann_dict.get(os.path.splitext(fn)[0], {}).get('annotations', [])\n",
        "        if not anns: continue\n",
        "        img_pil = Image.fromarray(arr[..., ::-1].astype(np.uint8))\n",
        "        mask_np = create_mask_binary(anns, arr.shape[:2])\n",
        "        aug = crop_fn(image=np.array(img_pil), mask=mask_np)\n",
        "        img_crop = Image.fromarray(aug['image'])\n",
        "        mask_crop = aug['mask']\n",
        "        imgs.append(seg_tf(img_crop))\n",
        "        masks.append(torch.from_numpy(mask_crop).long())\n",
        "    return imgs, masks"
      ],
      "metadata": {
        "id": "A7XFW8IZIH-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(pkls, mode='train'):\n",
        "    is_train = (mode=='train')\n",
        "    model.train() if is_train else model.eval()\n",
        "    total_loss, total_correct, total_pixels = 0.0, 0, 0\n",
        "    n_batches = sum((len(pickle.load(open(f,'rb'))) + seg_bs - 1)//seg_bs for f in pkls)\n",
        "    pbar = tqdm(total=n_batches, desc=f\"{mode.capitalize()} Epoch\", unit='batch', ncols=80)\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "        for fpath in pkls:\n",
        "            batch = pickle.load(open(fpath,'rb'))\n",
        "            for i in range(0, len(batch), seg_bs):\n",
        "                slice_batch = batch[i:i+seg_bs]\n",
        "                imgs, masks = process_slice(slice_batch)\n",
        "                if len(imgs) < 2:\n",
        "                    pbar.update(); continue\n",
        "                loader = DataLoader(TensorDataset(torch.stack(imgs), torch.stack(masks)),\n",
        "                                     batch_size=len(imgs), shuffle=is_train)\n",
        "                for x, y in loader:\n",
        "                    x, y = x.to(device), y.to(device)\n",
        "                    if is_train: optimizer.zero_grad()\n",
        "                    with autocast(): out = model(x)['out']; loss = criterion(out, y)\n",
        "                    if is_train:\n",
        "                        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "                    total_loss   += loss.item()\n",
        "                    preds        = out.argmax(dim=1)\n",
        "                    total_correct+= (preds==y).sum().item()\n",
        "                    total_pixels += y.numel()\n",
        "                    pbar.update()\n",
        "    pbar.close()\n",
        "    loss = total_loss / (total_pixels/(224*224)) if total_pixels else 0\n",
        "    acc  = total_correct/total_pixels if total_pixels else 0\n",
        "    return loss, acc"
      ],
      "metadata": {
        "id": "MOmOgiJbICgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "    tr_loss, tr_acc = run_epoch(train_pkls, 'train')\n",
        "    val_loss, val_acc = run_epoch(val_pkls, 'val')\n",
        "    torch.save(model.state_dict(), f\"deeplabv3_ep{epoch}.pth\")\n",
        "    print(f\"Epoch {epoch} | Train L:{tr_loss:.6f} A:{tr_acc:.4f} | Val L:{val_loss:.6f} A:{val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "UlkcS1YrH_Lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}