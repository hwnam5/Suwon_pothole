{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AsYEMd2LUFH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\n",
        "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
        "from torch.cuda.amp import autocast\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "DEVICE        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "WEIGHTS_PATH  = '/content/drive/MyDrive/pt_data/model_weights/deeplabv3_ep30.pth'\n",
        "NUM_CLASSES   = 2\n",
        "TOP_WIDTH_FRAC= 0.3\n",
        "BOTTOM_FRAC   = 0.5"
      ],
      "metadata": {
        "id": "ukjlhCQNLidF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform for input\n",
        "seg_tf = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "VyeWlh-zLgpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition and weight loading\n",
        "def get_deeplab_model(num_classes):\n",
        "    model = deeplabv3_resnet101(pretrained=False)\n",
        "    model.classifier = DeepLabHead(2048, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_deeplab_model(NUM_CLASSES).to(DEVICE)\n",
        "model.load_state_dict(torch.load(WEIGHTS_PATH, map_location=DEVICE))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "xu4-e7oyLe_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROI warp utilities\n",
        "def get_road_mask(img, margin=0.1):\n",
        "    h,w = img.shape[:2]\n",
        "    x0,x1 = int(w*margin), int(w*(1-margin))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    m = cv2.inRange(hsv, (0,0,60), (180,50,200))\n",
        "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE,\n",
        "                        cv2.getStructuringElement(cv2.MORPH_RECT,(15,15)))\n",
        "    m[:,:x0]=0; m[:,x1:]=0\n",
        "    return m"
      ],
      "metadata": {
        "id": "5QtAkiJcLc4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bottom_y(mask, bottom_frac=0.5):\n",
        "    h,_ = mask.shape\n",
        "    start = int(h*(1-bottom_frac))\n",
        "    ys = np.where(mask[start:,:].any(1))[0]\n",
        "    return (start+ys.max()) if ys.size else h"
      ],
      "metadata": {
        "id": "TLbcHS2CLbDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bottom_bounds(mask, yb, sample_n=5):\n",
        "    xs=[]\n",
        "    for dy in range(sample_n):\n",
        "        y = max(0,int(yb)-1-dy)\n",
        "        nz = np.where(mask[y]>0)[0]\n",
        "        if nz.size: xs.append([nz.min(), nz.max()])\n",
        "    if not xs: return 0.0, float(mask.shape[1])\n",
        "    arr = np.array(xs,np.float32)\n",
        "    return float(arr[:,0].mean()), float(arr[:,1].mean())"
      ],
      "metadata": {
        "id": "_PSjC6MvLZpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_vp_all(img):\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray,50,150)\n",
        "    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,\n",
        "                             minLineLength=50,maxLineGap=10)\n",
        "    if lines is None: return img.shape[1]/2, img.shape[0]*0.4\n",
        "    from itertools import combinations\n",
        "    pts=[]\n",
        "    for (x1,y1,x2,y2),(x3,y3,x4,y4) in combinations([l[0] for l in lines],2):\n",
        "        D=(x1-x2)*(y3-y4)-(y1-y2)*(x3-x4)\n",
        "        if abs(D)<1e-6: continue\n",
        "        px = ((x1*y2-y1*x2)*(x3-x4)-(x1-x2)*(x3*y4-y3*x4))/D\n",
        "        py = ((x1*y2-y1*x2)*(y3-y4)-(y1-y2)*(x3*y4-y3*x4))/D\n",
        "        if -img.shape[1]<px<2*img.shape[1] and -img.shape[0]<py<2*img.shape[0]:\n",
        "            pts.append((px,py))\n",
        "    if not pts: return img.shape[1]/2, img.shape[0]*0.4\n",
        "    return tuple(np.mean(pts, axis=0))"
      ],
      "metadata": {
        "id": "pozhKpr2LYpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def warp_roi(img, mask_bin, top_width_frac=TOP_WIDTH_FRAC, bottom_frac=BOTTOM_FRAC):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        img (np.ndarray): Original BGR image of shape (H, W, 3).\n",
        "        mask_bin (np.ndarray): Binary mask of shape (H, W), dtype uint8 with values 0 or 255.\n",
        "        top_width_frac (float): Fractional width at image top for ROI.\n",
        "        bottom_frac (float): Fractional bottom region height for ROI baseline.\n",
        "    Returns:\n",
        "        bird_img (np.ndarray): Warped and squared BGR image.\n",
        "        bird_mask (np.ndarray): Warped and squared binary mask.\n",
        "    \"\"\"\n",
        "    h,w = img.shape[:2]\n",
        "    road = get_road_mask(img)\n",
        "    yb = compute_bottom_y(road, bottom_frac)\n",
        "    xl,xr = compute_bottom_bounds(road, yb)\n",
        "    vp_x,vp_y = estimate_vp_all(img)\n",
        "    bw = xr - xl; tw = bw * top_width_frac; mid = (xl + xr)/2.0\n",
        "    src = np.array([[xl,yb],[xr,yb],[mid+tw/2,vp_y],[mid-tw/2,vp_y]],dtype=np.float32)\n",
        "    ys,xs = np.where(mask_bin>0)\n",
        "    if xs.size:\n",
        "        src[0,0] = min(src[0,0], xs.min())\n",
        "        src[1,0] = max(src[1,0], xs.max())\n",
        "    bird_w = max(int(src[1,0]-src[0,0]),1)\n",
        "    bird_h = max(int((src[0,1]-src[2,1])/top_width_frac),1)\n",
        "    dst = np.array([[0,bird_h],[bird_w,bird_h],[bird_w,0],[0,0]],dtype=np.float32)\n",
        "    M = cv2.getPerspectiveTransform(src,dst)\n",
        "    bird_img  = cv2.warpPerspective(img,M,(bird_w,bird_h))\n",
        "    bird_mask = cv2.warpPerspective(mask_bin,M,(bird_w,bird_h))\n",
        "    # square padding\n",
        "    h_b,w_b = bird_img.shape[:2]\n",
        "    if w_b< h_b:\n",
        "        pad = h_b-w_b; left=pad//2; right=pad-left\n",
        "        bird_img  = cv2.copyMakeBorder(bird_img,0,0,left,right,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
        "        bird_mask = cv2.copyMakeBorder(bird_mask,0,0,left,right,cv2.BORDER_CONSTANT,value=0)\n",
        "    elif w_b> h_b:\n",
        "        pad = w_b-h_b; top=pad//2; bot=pad-top\n",
        "        bird_img  = cv2.copyMakeBorder(bird_img,top,bot,0,0,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
        "        bird_mask = cv2.copyMakeBorder(bird_mask,top,bot,0,0,cv2.BORDER_CONSTANT,value=0)\n",
        "    return bird_img, bird_mask"
      ],
      "metadata": {
        "id": "-ma9AazSLXn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference & ROI Warp\n",
        "def infer_and_warp(img_np):\n",
        "    img_pil = Image.fromarray(img_np[...,::-1])\n",
        "    x = seg_tf(img_pil).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad(), autocast():\n",
        "        out = model(x)['out']\n",
        "    pred = out.argmax(1).squeeze(0).cpu().numpy().astype(np.uint8)\n",
        "    mask_bin = (pred>0).astype(np.uint8)*255\n",
        "    return warp_roi(img_np, mask_bin)"
      ],
      "metadata": {
        "id": "zneJVErtLVlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage:\n",
        "# if __name__ == '__main__':\n",
        "#     img = cv2.imread('path/to/image.jpg')\n",
        "#     warped_img, warped_mask = infer_and_warp(img)\n",
        "#     plt.subplot(1,2,1); plt.imshow(cv2.cvtColor(warped_img,cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "#     plt.subplot(1,2,2); plt.imshow(warped_mask, cmap='gray'); plt.axis('off')\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "hFhxW3TRLmNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}